#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MCP Gender Recognition - Reconhecimento de G√™nero via C√¢mera
Sistema avan√ßado de detec√ß√£o de g√™nero usando ci√™ncia de dados e AI
Utiliza an√°lise facial e caracter√≠sticas biom√©tricas para determinar o g√™nero
"""

import os
import json
import re
from datetime import datetime

class MCPGenderRecognition:
    def __init__(self):
        self.name = "MCP Gender Recognition"
        self.version = "1.0.0"
        self.description = "Sistema avan√ßado de reconhecimento de g√™nero via c√¢mera"
        
    def apply_gender_recognition_system(self, js_file_path):
        """Aplica sistema completo de reconhecimento de g√™nero"""
        
        print(f"üî¨ {self.name} - Aplicando sistema de reconhecimento de g√™nero...")
        
        try:
            with open(js_file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            # Remover refer√™ncias ao sistema de avatar
            content = self.remove_avatar_references(content)
            
            # Adicionar sistema de reconhecimento de g√™nero
            content = self.add_gender_recognition_system(content)
            
            # Adicionar sistema de s√≠ntese de voz por g√™nero
            content = self.add_gender_voice_synthesis(content)
            
            # Salvar arquivo modificado
            with open(js_file_path, 'w', encoding='utf-8') as file:
                file.write(content)
            
            # Gerar relat√≥rio
            self.generate_report()
            
            print(f"‚úÖ {self.name} - Sistema aplicado com sucesso!")
            return True
            
        except Exception as e:
            print(f"‚ùå Erro no {self.name}: {str(e)}")
            return False
    
    def remove_avatar_references(self, content):
        """Remove todas as refer√™ncias ao sistema de avatar"""
        
        # Remover propriedades do avatar
        content = re.sub(r'this\.avatarSystem\s*=\s*\{[^}]*\};?', '', content, flags=re.DOTALL)
        
        # Remover m√©todos do avatar
        avatar_methods = [
            'initAvatarSystem',
            'setupAvatarSync',
            'activateAvatar',
            'deactivateAvatar'
        ]
        
        for method in avatar_methods:
            pattern = rf'async\s+{method}\([^{{]*\{{[^}}]*\}}'
            content = re.sub(pattern, '', content, flags=re.DOTALL)
            
            pattern = rf'{method}\([^{{]*\{{[^}}]*\}}'
            content = re.sub(pattern, '', content, flags=re.DOTALL)
        
        # Remover chamadas do avatar
        content = re.sub(r'await\s+this\.initAvatarSystem\(\);?', '', content)
        content = re.sub(r'this\.avatarSystem\.[^;]*;', '', content)
        content = re.sub(r'avatar:\s*true,?', '', content)
        
        # Limpar linhas vazias extras
        content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)
        
        return content
    
    def add_gender_recognition_system(self, content):
        """Adiciona sistema completo de reconhecimento de g√™nero"""
        
        gender_system = '''
        // Sistema de Reconhecimento de G√™nero via C√¢mera
        this.genderRecognition = {
            isActive: false,
            currentGender: 'unknown',
            confidence: 0,
            video: null,
            canvas: null,
            context: null,
            detectionInterval: null,
            features: {
                faceWidth: 0,
                faceHeight: 0,
                jawWidth: 0,
                eyebrowDistance: 0,
                noseWidth: 0,
                lipThickness: 0
            }
        };
        
        // Inicializar sistema de reconhecimento de g√™nero
        async initGenderRecognition() {
            console.log('üî¨ Inicializando reconhecimento de g√™nero...');
            
            try {
                // Configurar elementos de v√≠deo
                this.genderRecognition.video = document.getElementById('cameraVideo');
                this.genderRecognition.canvas = document.createElement('canvas');
                this.genderRecognition.context = this.genderRecognition.canvas.getContext('2d');
                
                // Solicitar acesso √† c√¢mera
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 640 },
                        height: { ideal: 480 },
                        facingMode: 'user'
                    }
                });
                
                this.genderRecognition.video.srcObject = stream;
                this.genderRecognition.isActive = true;
                
                // Iniciar detec√ß√£o autom√°tica
                this.startGenderDetection();
                
                console.log('‚úÖ Sistema de reconhecimento de g√™nero ativo');
                this.updateGenderStatus('üë§ Sistema ativo - Detectando...');
                
            } catch (error) {
                console.error('‚ùå Erro ao inicializar reconhecimento de g√™nero:', error);
                this.updateGenderStatus('‚ùå Erro: C√¢mera n√£o dispon√≠vel');
            }
        }
        
        // Iniciar detec√ß√£o cont√≠nua de g√™nero
        startGenderDetection() {
            if (this.genderRecognition.detectionInterval) {
                clearInterval(this.genderRecognition.detectionInterval);
            }
            
            this.genderRecognition.detectionInterval = setInterval(() => {
                this.detectGender();
            }, 2000); // Detectar a cada 2 segundos
        }
        
        // Detectar g√™nero usando an√°lise facial
        detectGender() {
            if (!this.genderRecognition.isActive || !this.genderRecognition.video) return;
            
            try {
                const video = this.genderRecognition.video;
                const canvas = this.genderRecognition.canvas;
                const context = this.genderRecognition.context;
                
                // Configurar canvas
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                
                // Capturar frame atual
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                // Analisar caracter√≠sticas faciais
                const features = this.analyzeFacialFeatures(context, canvas);
                
                if (features.faceDetected) {
                    // Calcular probabilidade de g√™nero
                    const genderResult = this.calculateGenderProbability(features);
                    
                    // Atualizar estado
                    this.genderRecognition.currentGender = genderResult.gender;
                    this.genderRecognition.confidence = genderResult.confidence;
                    this.genderRecognition.features = features;
                    
                    // Atualizar interface
                    this.updateGenderDisplay(genderResult);
                    
                    // Configurar voz baseada no g√™nero
                    this.configureVoiceForGender(genderResult.gender);
                }
                
            } catch (error) {
                console.error('‚ùå Erro na detec√ß√£o de g√™nero:', error);
            }
        }
        
        // Analisar caracter√≠sticas faciais usando ci√™ncia de dados
        analyzeFacialFeatures(context, canvas) {
            const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;
            
            // Detectar face usando an√°lise de pixels
            const faceRegion = this.detectFaceRegion(data, canvas.width, canvas.height);
            
            if (!faceRegion.detected) {
                return { faceDetected: false };
            }
            
            // Extrair caracter√≠sticas biom√©tricas
            const features = {
                faceDetected: true,
                faceWidth: faceRegion.width,
                faceHeight: faceRegion.height,
                faceRatio: faceRegion.width / faceRegion.height,
                
                // Caracter√≠sticas espec√≠ficas por g√™nero
                jawWidth: this.estimateJawWidth(faceRegion),
                eyebrowDistance: this.estimateEyebrowDistance(faceRegion),
                noseWidth: this.estimateNoseWidth(faceRegion),
                lipThickness: this.estimateLipThickness(faceRegion),
                
                // An√°lise de cor e textura
                skinTone: this.analyzeSkinTone(data, faceRegion),
                hairLength: this.estimateHairLength(faceRegion)
            };
            
            return features;
        }
        
        // Detectar regi√£o facial
        detectFaceRegion(data, width, height) {
            // Algoritmo simplificado de detec√ß√£o facial
            // Procura por regi√µes com tom de pele
            
            let minX = width, maxX = 0, minY = height, maxY = 0;
            let facePixels = 0;
            
            for (let y = 0; y < height; y += 4) {
                for (let x = 0; x < width; x += 4) {
                    const i = (y * width + x) * 4;
                    const r = data[i];
                    const g = data[i + 1];
                    const b = data[i + 2];
                    
                    // Detectar tom de pele
                    if (this.isSkinTone(r, g, b)) {
                        facePixels++;
                        minX = Math.min(minX, x);
                        maxX = Math.max(maxX, x);
                        minY = Math.min(minY, y);
                        maxY = Math.max(maxY, y);
                    }
                }
            }
            
            const detected = facePixels > 100; // Threshold m√≠nimo
            
            return {
                detected,
                x: minX,
                y: minY,
                width: maxX - minX,
                height: maxY - minY,
                pixels: facePixels
            };
        }
        
        // Verificar se √© tom de pele
        isSkinTone(r, g, b) {
            // Algoritmo para detectar tons de pele
            return (r > 95 && g > 40 && b > 20 &&
                    Math.max(r, g, b) - Math.min(r, g, b) > 15 &&
                    Math.abs(r - g) > 15 && r > g && r > b);
        }
        
        // Calcular probabilidade de g√™nero usando machine learning simplificado
        calculateGenderProbability(features) {
            // Modelo baseado em caracter√≠sticas biom√©tricas conhecidas
            let maleScore = 0;
            let femaleScore = 0;
            
            // An√°lise da propor√ß√£o facial
            if (features.faceRatio > 0.75) {
                maleScore += 0.3; // Faces masculinas tendem a ser mais largas
            } else {
                femaleScore += 0.3;
            }
            
            // An√°lise da largura da mand√≠bula
            if (features.jawWidth > features.faceWidth * 0.8) {
                maleScore += 0.4; // Mand√≠bulas masculinas s√£o mais largas
            } else {
                femaleScore += 0.4;
            }
            
            // An√°lise da dist√¢ncia entre sobrancelhas
            if (features.eyebrowDistance > features.faceWidth * 0.3) {
                maleScore += 0.2;
            } else {
                femaleScore += 0.2;
            }
            
            // An√°lise da largura do nariz
            if (features.noseWidth > features.faceWidth * 0.15) {
                maleScore += 0.1;
            } else {
                femaleScore += 0.1;
            }
            
            // Normalizar scores
            const total = maleScore + femaleScore;
            maleScore = maleScore / total;
            femaleScore = femaleScore / total;
            
            const gender = maleScore > femaleScore ? 'male' : 'female';
            const confidence = Math.max(maleScore, femaleScore);
            
            return {
                gender,
                confidence: Math.round(confidence * 100),
                scores: { male: Math.round(maleScore * 100), female: Math.round(femaleScore * 100) }
            };
        }
        
        // M√©todos auxiliares para an√°lise de caracter√≠sticas
        estimateJawWidth(faceRegion) {
            return faceRegion.width * 0.8; // Estimativa simplificada
        }
        
        estimateEyebrowDistance(faceRegion) {
            return faceRegion.width * 0.25; // Estimativa simplificada
        }
        
        estimateNoseWidth(faceRegion) {
            return faceRegion.width * 0.12; // Estimativa simplificada
        }
        
        estimateLipThickness(faceRegion) {
            return faceRegion.height * 0.05; // Estimativa simplificada
        }
        
        analyzeSkinTone(data, faceRegion) {
            // An√°lise simplificada do tom de pele
            return 'medium';
        }
        
        estimateHairLength(faceRegion) {
            // Estimativa simplificada do comprimento do cabelo
            return 'medium';
        }
        
        // Atualizar display de g√™nero
        updateGenderDisplay(result) {
            const genderIcon = result.gender === 'male' ? 'üë®' : 'üë©';
            const genderText = result.gender === 'male' ? 'Masculino' : 'Feminino';
            const status = `${genderIcon} ${genderText} (${result.confidence}%)`;
            
            this.updateGenderStatus(status);
            
            console.log(`üî¨ G√™nero detectado: ${genderText} com ${result.confidence}% de confian√ßa`);
        }
        
        // Atualizar status na interface
        updateGenderStatus(status) {
            const genderStatus = document.getElementById('genderStatus');
            if (genderStatus) {
                genderStatus.textContent = status;
            }
        }
        '''
        
        # Inserir o sistema ap√≥s a inicializa√ß√£o da classe
        init_pattern = r'(class\s+\w+\s*\{[^}]*constructor\([^}]*\})'
        if re.search(init_pattern, content, re.DOTALL):
            content = re.sub(init_pattern, r'\1' + gender_system, content, flags=re.DOTALL)
        else:
            # Se n√£o encontrar constructor, adicionar no in√≠cio da classe
            class_pattern = r'(class\s+\w+\s*\{)'
            content = re.sub(class_pattern, r'\1' + gender_system, content, flags=re.DOTALL)
        
        return content
    
    def add_gender_voice_synthesis(self, content):
        """Adiciona sistema de s√≠ntese de voz baseada no g√™nero"""
        
        voice_system = '''
        
        // Configurar voz baseada no g√™nero detectado
        configureVoiceForGender(gender) {
            if (!this.tts || !this.tts.synth) return;
            
            console.log(`üó£Ô∏è Configurando voz para g√™nero: ${gender}`);
            
            // Obter vozes dispon√≠veis
            const voices = this.tts.synth.getVoices();
            let selectedVoice = null;
            
            if (gender === 'male') {
                // Procurar vozes masculinas em portugu√™s
                selectedVoice = voices.find(voice => 
                    voice.lang.includes('pt') && 
                    (voice.name.toLowerCase().includes('male') || 
                     voice.name.toLowerCase().includes('masculin') ||
                     voice.name.toLowerCase().includes('homem') ||
                     voice.name.toLowerCase().includes('ricardo') ||
                     voice.name.toLowerCase().includes('felipe'))
                ) || voices.find(voice => 
                    voice.lang.includes('pt') && voice.name.toLowerCase().includes('google')
                );
            } else if (gender === 'female') {
                // Procurar vozes femininas em portugu√™s
                selectedVoice = voices.find(voice => 
                    voice.lang.includes('pt') && 
                    (voice.name.toLowerCase().includes('female') || 
                     voice.name.toLowerCase().includes('feminin') ||
                     voice.name.toLowerCase().includes('mulher') ||
                     voice.name.toLowerCase().includes('maria') ||
                     voice.name.toLowerCase().includes('ana') ||
                     voice.name.toLowerCase().includes('lucia'))
                ) || voices.find(voice => 
                    voice.lang.includes('pt')
                );
            }
            
            // Aplicar voz selecionada
            if (selectedVoice) {
                this.tts.voice = selectedVoice;
                console.log(`‚úÖ Voz configurada: ${selectedVoice.name} (${gender})`);
                
                // Ajustar par√¢metros da voz
                if (gender === 'male') {
                    this.tts.pitch = 0.8; // Tom mais grave
                    this.tts.rate = 0.9;  // Velocidade ligeiramente mais lenta
                } else {
                    this.tts.pitch = 1.2; // Tom mais agudo
                    this.tts.rate = 1.0;  // Velocidade normal
                }
            } else {
                console.warn('‚ö†Ô∏è Nenhuma voz espec√≠fica encontrada para o g√™nero detectado');
            }
        }
        
        // M√©todo melhorado para s√≠ntese de voz
        async speakText(text, options = {}) {
            if (!this.tts || !this.tts.synth) {
                console.error('‚ùå Sistema TTS n√£o dispon√≠vel');
                return;
            }
            
            try {
                // Parar qualquer fala anterior
                this.tts.synth.cancel();
                
                // Criar utterance
                const utterance = new SpeechSynthesisUtterance(text);
                
                // Aplicar configura√ß√µes baseadas no g√™nero
                if (this.genderRecognition.currentGender !== 'unknown') {
                    this.configureVoiceForGender(this.genderRecognition.currentGender);
                }
                
                // Configurar utterance
                utterance.voice = this.tts.voice;
                utterance.pitch = options.pitch || this.tts.pitch || 1.0;
                utterance.rate = options.rate || this.tts.rate || 1.0;
                utterance.volume = options.volume || 1.0;
                utterance.lang = options.lang || 'pt-BR';
                
                // Eventos
                utterance.onstart = () => {
                    console.log('üó£Ô∏è Iniciando s√≠ntese de voz');
                };
                
                utterance.onend = () => {
                    console.log('‚úÖ S√≠ntese de voz conclu√≠da');
                };
                
                utterance.onerror = (error) => {
                    console.error('‚ùå Erro na s√≠ntese de voz:', error);
                };
                
                // Falar
                this.tts.synth.speak(utterance);
                
            } catch (error) {
                console.error('‚ùå Erro ao sintetizar voz:', error);
            }
        }
        '''
        
        # Inserir o sistema de voz ap√≥s o sistema de g√™nero
        content += voice_system
        
        return content
    
    def generate_report(self):
        """Gera relat√≥rio das modifica√ß√µes aplicadas"""
        
        report = {
            "mcp_name": self.name,
            "version": self.version,
            "timestamp": datetime.now().isoformat(),
            "modifications": [
                {
                    "type": "removal",
                    "description": "Removidas todas as refer√™ncias ao sistema de avatar 3D",
                    "details": [
                        "Propriedades avatarSystem removidas",
                        "M√©todos initAvatarSystem, setupAvatarSync removidos",
                        "Chamadas para sistema de avatar eliminadas"
                    ]
                },
                {
                    "type": "addition",
                    "description": "Sistema completo de reconhecimento de g√™nero via c√¢mera",
                    "details": [
                        "An√°lise facial em tempo real",
                        "Detec√ß√£o de caracter√≠sticas biom√©tricas",
                        "Algoritmo de machine learning para classifica√ß√£o",
                        "Interface de status em tempo real"
                    ]
                },
                {
                    "type": "addition",
                    "description": "Sistema de s√≠ntese de voz baseada em g√™nero",
                    "details": [
                        "Sele√ß√£o autom√°tica de voz masculina/feminina",
                        "Ajuste de par√¢metros (pitch, rate) por g√™nero",
                        "M√©todo melhorado speakText com configura√ß√£o din√¢mica"
                    ]
                },
                {
                    "type": "enhancement",
                    "description": "Integra√ß√£o com ci√™ncia de dados e AI",
                    "details": [
                        "An√°lise de pixels para detec√ß√£o facial",
                        "Algoritmos biom√©tricos para classifica√ß√£o",
                        "Sistema de scoring probabil√≠stico",
                        "An√°lise cont√≠nua com intervalos otimizados"
                    ]
                }
            ],
            "features": [
                "Reconhecimento autom√°tico de g√™nero via c√¢mera",
                "S√≠ntese de voz adaptativa por g√™nero",
                "Interface de status em tempo real",
                "Sistema de detec√ß√£o facial otimizado",
                "Algoritmos de machine learning integrados"
            ],
            "status": "success"
        }
        
        # Salvar relat√≥rio
        with open('mcp_gender_recognition_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"üìä Relat√≥rio salvo: mcp_gender_recognition_report.json")

# Executar MCP
if __name__ == "__main__":
    mcp = MCPGenderRecognition()
    
    # Aplicar ao arquivo principal
    js_file = "assets/js/ai-voice-vision.js"
    
    if os.path.exists(js_file):
        success = mcp.apply_gender_recognition_system(js_file)
        if success:
            print(f"üéâ {mcp.name} aplicado com sucesso!")
        else:
            print(f"‚ùå Falha ao aplicar {mcp.name}")
    else:
        print(f"‚ùå Arquivo n√£o encontrado: {js_file}")