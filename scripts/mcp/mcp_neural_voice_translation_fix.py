#!/usr/bin/env python3
"""
MCP Neural Voice Translation Fix
Especializado em RNN/CNN para diagnosticar e corrigir problemas de tradu√ß√£o por voz
"""

import os
import re
import json
from datetime import datetime

class NeuralVoiceTranslationFix:
    def __init__(self, project_root):
        self.project_root = project_root
        self.web_dir = os.path.join(project_root, 'web')
        self.script_path = os.path.join(self.web_dir, 'assets', 'js', 'script.js')
        self.fixes_applied = []
        self.neural_analysis = {
            'voice_recognition_patterns': [],
            'translation_flow_issues': [],
            'error_handling_gaps': [],
            'performance_bottlenecks': []
        }
    
    def analyze_voice_translation_flow(self):
        """An√°lise neural do fluxo de tradu√ß√£o por voz usando padr√µes RNN/CNN"""
        print("üß† Iniciando an√°lise neural do fluxo de tradu√ß√£o por voz...")
        
        with open(self.script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Padr√£o RNN: An√°lise sequencial do fluxo de dados
        self._analyze_sequential_flow(content)
        
        # Padr√£o CNN: An√°lise de caracter√≠sticas locais e globais
        self._analyze_feature_patterns(content)
        
        # Identificar gargalos de performance
        self._identify_performance_bottlenecks(content)
        
        return self.neural_analysis
    
    def _analyze_sequential_flow(self, content):
        """An√°lise sequencial usando padr√µes RNN"""
        print("üîÑ An√°lise RNN: Fluxo sequencial de dados...")
        
        # Mapear o fluxo: Voz -> Reconhecimento -> Texto -> Tradu√ß√£o -> Resultado
        flow_patterns = [
            r'recognition\.onresult.*?=.*?async.*?\(event\)',
            r'translateTextWithSpeech\(',
            r'callTranslationAPI\(',
            r'elements\.targetText\.value\s*=',
            r'speakTranslation\('
        ]
        
        for i, pattern in enumerate(flow_patterns):
            matches = re.findall(pattern, content, re.DOTALL)
            if matches:
                self.neural_analysis['voice_recognition_patterns'].append({
                    'step': i + 1,
                    'pattern': pattern,
                    'found': True,
                    'count': len(matches)
                })
            else:
                self.neural_analysis['translation_flow_issues'].append({
                    'step': i + 1,
                    'pattern': pattern,
                    'issue': 'Pattern not found in expected sequence'
                })
    
    def _analyze_feature_patterns(self, content):
        """An√°lise de caracter√≠sticas usando padr√µes CNN"""
        print("üéØ An√°lise CNN: Caracter√≠sticas locais e globais...")
        
        # Caracter√≠sticas cr√≠ticas para tradu√ß√£o por voz
        critical_features = {
            'error_handling_in_voice': r'catch\s*\([^)]*\)\s*\{[^}]*voice|voice[^}]*catch',
            'async_await_pattern': r'async.*?translateTextWithSpeech|translateTextWithSpeech.*?await',
            'speech_error_recovery': r'onerror.*?=.*?function|onerror.*?=>',
            'translation_timeout': r'timeout|AbortController',
            'voice_state_management': r'speech\.active|recognition\.active|isListening'
        }
        
        for feature_name, pattern in critical_features.items():
            matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
            if not matches:
                self.neural_analysis['error_handling_gaps'].append({
                    'feature': feature_name,
                    'pattern': pattern,
                    'status': 'missing_or_inadequate'
                })
    
    def _identify_performance_bottlenecks(self, content):
        """Identificar gargalos de performance"""
        print("‚ö° Identificando gargalos de performance...")
        
        # Procurar por padr√µes que podem causar lentid√£o
        bottleneck_patterns = {
            'synchronous_translation': r'translateTextWithSpeech\([^)]*\)(?!\s*\.then|\s*await)',
            'missing_debounce': r'addEventListener.*input.*translateText',
            'excessive_logging': r'console\.log.*translation|console\.error.*translation',
            'blocking_operations': r'\.value\s*\+=.*finalTranscript'
        }
        
        for bottleneck_name, pattern in bottleneck_patterns.items():
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                self.neural_analysis['performance_bottlenecks'].append({
                    'bottleneck': bottleneck_name,
                    'occurrences': len(matches),
                    'severity': 'high' if len(matches) > 3 else 'medium'
                })
    
    def apply_neural_fixes(self):
        """Aplicar corre√ß√µes baseadas na an√°lise neural"""
        print("üîß Aplicando corre√ß√µes neurais...")
        
        with open(self.script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Fix 1: Melhorar tratamento de erro na tradu√ß√£o por voz
        content = self._fix_voice_translation_error_handling(content)
        
        # Fix 2: Adicionar timeout espec√≠fico para tradu√ß√£o por voz
        content = self._add_voice_translation_timeout(content)
        
        # Fix 3: Implementar retry autom√°tico para falhas de tradu√ß√£o por voz
        content = self._add_voice_translation_retry(content)
        
        # Fix 4: Adicionar logs detalhados para diagn√≥stico
        content = self._add_neural_diagnostic_logs(content)
        
        # Salvar arquivo corrigido
        with open(self.script_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return self.fixes_applied
    
    def _fix_voice_translation_error_handling(self, content):
        """Corrigir tratamento de erro espec√≠fico para tradu√ß√£o por voz"""
        print("üõ†Ô∏è Corrigindo tratamento de erro na tradu√ß√£o por voz...")
        
        # Encontrar e substituir a fun√ß√£o translateTextWithSpeech
        pattern = r'async translateTextWithSpeech\(isAutoTranslate = false\) \{[^}]*(?:\{[^}]*\}[^}]*)*\}'
        
        new_function = '''async translateTextWithSpeech(isAutoTranslate = false) {
        console.log('üé§ NEURAL: Iniciando tradu√ß√£o por voz', { isAutoTranslate });
        
        const sourceText = this.elements.sourceText.value.trim();
        if (!sourceText) {
            console.log('üé§ NEURAL: Texto vazio, abortando tradu√ß√£o');
            return;
        }
        
        const sourceLang = this.elements.sourceLanguage.value;
        const targetLang = this.elements.targetLanguage.value;
        
        if (sourceLang === targetLang) {
            console.log('üé§ NEURAL: Idiomas iguais, abortando tradu√ß√£o');
            return;
        }
        
        // S√≥ mostrar overlay se n√£o for tradu√ß√£o autom√°tica
        if (!isAutoTranslate) {
            this.showLoading(true);
        }
        this.elements.translationStatus.textContent = 'Traduzindo por voz...';
        
        const startTime = Date.now();
        let retryCount = 0;
        const maxRetries = 3;
        
        while (retryCount < maxRetries) {
            try {
                console.log(`üé§ NEURAL: Tentativa ${retryCount + 1}/${maxRetries} de tradu√ß√£o`);
                
                // Timeout espec√≠fico para tradu√ß√£o por voz (mais curto)
                const controller = new AbortController();
                const timeoutId = setTimeout(() => controller.abort(), 8000);
                
                const translation = await Promise.race([
                    this.callTranslationAPI(sourceText, sourceLang, targetLang),
                    new Promise((_, reject) => 
                        setTimeout(() => reject(new Error('Voice translation timeout')), 8000)
                    )
                ]);
                
                clearTimeout(timeoutId);
                
                if (translation && translation.trim()) {
                    const processingTime = Date.now() - startTime;
                    
                    this.elements.targetText.value = translation;
                    this.elements.translationStatus.textContent = 'Tradu√ß√£o por voz conclu√≠da';
                    this.elements.processingTime.textContent = `${processingTime}ms`;
                    
                    // Adicionar ao hist√≥rico
                    this.addToHistory(sourceText, translation, sourceLang, targetLang);
                    
                    console.log('‚úÖ NEURAL: Tradu√ß√£o por voz bem-sucedida:', translation);
                    
                    // Falar a tradu√ß√£o automaticamente
                    this.speakTranslation(translation, targetLang);
                    
                    break; // Sucesso, sair do loop
                } else {
                    throw new Error('Tradu√ß√£o vazia recebida');
                }
                
            } catch (error) {
                retryCount++;
                console.error(`‚ùå NEURAL: Erro na tentativa ${retryCount}:`, error);
                
                if (retryCount >= maxRetries) {
                    // Usar tradu√ß√£o de emerg√™ncia como √∫ltimo recurso
                    console.log('üö® NEURAL: Usando tradu√ß√£o de emerg√™ncia para voz');
                    
                    try {
                        const emergencyTranslation = this.getOfflineTranslation(sourceText, sourceLang, targetLang);
                        if (emergencyTranslation) {
                            this.elements.targetText.value = emergencyTranslation;
                            this.elements.translationStatus.textContent = 'Tradu√ß√£o offline (voz)';
                            console.log('‚úÖ NEURAL: Tradu√ß√£o de emerg√™ncia aplicada:', emergencyTranslation);
                            this.speakTranslation(emergencyTranslation, targetLang);
                        } else {
                            throw new Error('Tradu√ß√£o de emerg√™ncia tamb√©m falhou');
                        }
                    } catch (emergencyError) {
                        console.error('‚ùå NEURAL: Falha total na tradu√ß√£o por voz:', emergencyError);
                        this.elements.translationStatus.textContent = 'Erro: Tradu√ß√£o por voz falhou';
                        this.elements.targetText.value = 'Erro: N√£o foi poss√≠vel traduzir o texto por voz. Tente digitar manualmente.';
                    }
                } else {
                    // Aguardar antes da pr√≥xima tentativa
                    await new Promise(resolve => setTimeout(resolve, 1000 * retryCount));
                }
            }
        }
        
        // S√≥ esconder overlay se n√£o for tradu√ß√£o autom√°tica
        if (!isAutoTranslate) {
            this.showLoading(false);
        }
    }'''
        
        if re.search(pattern, content, re.DOTALL):
            content = re.sub(pattern, new_function, content, flags=re.DOTALL)
            self.fixes_applied.append("Tratamento de erro neural para tradu√ß√£o por voz")
        
        return content
    
    def _add_voice_translation_timeout(self, content):
        """Adicionar timeout espec√≠fico para tradu√ß√£o por voz"""
        # J√° implementado na fun√ß√£o anterior
        return content
    
    def _add_voice_translation_retry(self, content):
        """Adicionar retry autom√°tico para falhas de tradu√ß√£o por voz"""
        # J√° implementado na fun√ß√£o anterior
        return content
    
    def _add_neural_diagnostic_logs(self, content):
        """Adicionar logs de diagn√≥stico neural"""
        print("üìä Adicionando logs de diagn√≥stico neural...")
        
        # Adicionar logs na fun√ß√£o onresult
        old_onresult = r'this\.speech\.recognition\.onresult = async \(event\) => \{'
        new_onresult = '''this.speech.recognition.onresult = async (event) => {
            console.log('üß† NEURAL: Evento onresult recebido', { 
                resultIndex: event.resultIndex, 
                resultsLength: event.results.length 
            });'''
        
        content = re.sub(old_onresult, new_onresult, content)
        
        self.fixes_applied.append("Logs de diagn√≥stico neural adicionados")
        return content
    
    def generate_report(self):
        """Gerar relat√≥rio da an√°lise e corre√ß√µes neurais"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'analysis': self.neural_analysis,
            'fixes_applied': self.fixes_applied,
            'recommendations': [
                'Monitorar logs NEURAL para identificar padr√µes de falha',
                'Testar tradu√ß√£o por voz em diferentes navegadores',
                'Verificar lat√™ncia de rede durante tradu√ß√£o por voz',
                'Considerar implementar cache local para tradu√ß√µes frequentes'
            ]
        }
        
        report_path = os.path.join(self.web_dir, 'neural_voice_translation_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        return report

def main():
    project_root = r"C:\Users\flavi\Documents\GitHub\NeuroTranslator_PT_EN"
    
    print("üß† MCP Neural Voice Translation Fix - Iniciando...")
    
    fixer = NeuralVoiceTranslationFix(project_root)
    
    # An√°lise neural
    analysis = fixer.analyze_voice_translation_flow()
    print(f"üìä An√°lise conclu√≠da: {len(analysis['translation_flow_issues'])} problemas identificados")
    
    # Aplicar corre√ß√µes
    fixes = fixer.apply_neural_fixes()
    print(f"üîß {len(fixes)} corre√ß√µes aplicadas")
    
    # Gerar relat√≥rio
    report = fixer.generate_report()
    print(f"üìã Relat√≥rio salvo: neural_voice_translation_report.json")
    
    print("‚úÖ MCP Neural Voice Translation Fix conclu√≠do!")
    
    return report

if __name__ == "__main__":
    main()