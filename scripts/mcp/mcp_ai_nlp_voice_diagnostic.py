#!/usr/bin/env python3
"""
ü§ñ MCP AI/NLP Voice Translation Diagnostic
Sistema especializado em Intelig√™ncia Artificial e Processamento de Linguagem Natural
para diagnosticar e corrigir problemas espec√≠ficos de tradu√ß√£o por voz
"""

import json
import re
import os
from datetime import datetime
from typing import Dict, List, Any, Tuple

class AIVoiceTranslationDiagnostic:
    """
    Sistema AI/NLP para diagn√≥stico avan√ßado de tradu√ß√£o por voz
    Utiliza t√©cnicas de NLP para analisar fluxo de processamento de linguagem
    """
    
    def __init__(self):
        self.web_dir = "web"
        self.analysis_results = {
            "timestamp": datetime.now().isoformat(),
            "ai_nlp_analysis": {
                "speech_recognition_pipeline": {},
                "text_processing_flow": {},
                "translation_api_analysis": {},
                "voice_synthesis_integration": {},
                "error_pattern_analysis": {}
            },
            "identified_issues": [],
            "nlp_recommendations": [],
            "applied_fixes": []
        }
        
    def run_comprehensive_analysis(self):
        """Executar an√°lise completa AI/NLP do sistema de voz"""
        print("ü§ñ AI/NLP: Iniciando diagn√≥stico avan√ßado de tradu√ß√£o por voz...")
        
        # 1. Analisar pipeline de reconhecimento de voz
        self._analyze_speech_recognition_pipeline()
        
        # 2. Analisar processamento de texto com NLP
        self._analyze_text_processing_flow()
        
        # 3. Analisar chamadas de API de tradu√ß√£o
        self._analyze_translation_api_calls()
        
        # 4. Analisar integra√ß√£o com s√≠ntese de voz
        self._analyze_voice_synthesis_integration()
        
        # 5. An√°lise de padr√µes de erro com NLP
        self._analyze_error_patterns()
        
        # 6. Identificar problemas espec√≠ficos
        self._identify_specific_issues()
        
        print("‚úÖ AI/NLP: An√°lise completa finalizada")
        
    def _analyze_speech_recognition_pipeline(self):
        """An√°lise AI/NLP do pipeline de reconhecimento de voz"""
        print("üé§ AI/NLP: Analisando pipeline de speech-to-text...")
        
        script_path = os.path.join(self.web_dir, "assets", "js", "script.js")
        
        if not os.path.exists(script_path):
            print(f"‚ùå Arquivo n√£o encontrado: {script_path}")
            return
            
        with open(script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        pipeline_analysis = {
            "recognition_initialization": [],
            "language_configuration": [],
            "result_processing": [],
            "interim_results_handling": [],
            "confidence_scoring": []
        }
        
        # Analisar inicializa√ß√£o do reconhecimento
        init_patterns = re.findall(r'new\s+webkitSpeechRecognition\(\)|new\s+SpeechRecognition\(\)', content)
        pipeline_analysis["recognition_initialization"] = init_patterns
        
        # Analisar configura√ß√£o de idioma
        lang_patterns = re.findall(r'recognition\.lang\s*=\s*[\'"][^\'"]+[\'"]', content)
        pipeline_analysis["language_configuration"] = lang_patterns
        
        # Analisar processamento de resultados
        result_patterns = re.findall(r'recognition\.onresult\s*=.*?transcript', content, re.DOTALL)
        pipeline_analysis["result_processing"] = result_patterns
        
        # Analisar resultados intermedi√°rios
        interim_patterns = re.findall(r'interimResults\s*=\s*true', content)
        pipeline_analysis["interim_results_handling"] = interim_patterns
        
        self.analysis_results["ai_nlp_analysis"]["speech_recognition_pipeline"] = pipeline_analysis
        print(f"üìä AI/NLP: Pipeline analisado - {len(init_patterns)} inicializa√ß√µes encontradas")
        
    def _analyze_text_processing_flow(self):
        """An√°lise NLP do fluxo de processamento de texto"""
        print("üìù NLP: Analisando processamento de texto...")
        
        script_path = os.path.join(self.web_dir, "assets", "js", "script.js")
        
        with open(script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        text_flow = {
            "text_extraction": [],
            "text_cleaning": [],
            "language_detection": [],
            "text_validation": [],
            "preprocessing_steps": []
        }
        
        # Analisar extra√ß√£o de texto
        extraction_patterns = re.findall(r'transcript\s*=\s*[^;]+', content)
        text_flow["text_extraction"] = extraction_patterns
        
        # Analisar limpeza de texto
        cleaning_patterns = re.findall(r'\.trim\(\)|\.replace\([^)]+\)', content)
        text_flow["text_cleaning"] = cleaning_patterns
        
        # Analisar valida√ß√£o de texto
        validation_patterns = re.findall(r'if\s*\([^)]*text[^)]*\)', content)
        text_flow["text_validation"] = validation_patterns
        
        self.analysis_results["ai_nlp_analysis"]["text_processing_flow"] = text_flow
        print(f"üîç NLP: Processamento analisado - {len(validation_patterns)} valida√ß√µes encontradas")
        
    def _analyze_translation_api_calls(self):
        """An√°lise AI das chamadas de API de tradu√ß√£o"""
        print("üåê AI: Analisando chamadas de API de tradu√ß√£o...")
        
        script_path = os.path.join(self.web_dir, "assets", "js", "script.js")
        
        with open(script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        api_analysis = {
            "api_endpoints": [],
            "request_methods": [],
            "error_handling": [],
            "timeout_configuration": [],
            "retry_mechanisms": [],
            "response_processing": []
        }
        
        # Analisar endpoints de API
        endpoint_patterns = re.findall(r'fetch\([\'"][^\'"]+[\'"]', content)
        api_analysis["api_endpoints"] = endpoint_patterns
        
        # Analisar m√©todos de requisi√ß√£o
        method_patterns = re.findall(r'method:\s*[\'"][^\'"]+[\'"]', content)
        api_analysis["request_methods"] = method_patterns
        
        # Analisar tratamento de erro
        error_patterns = re.findall(r'catch\s*\([^)]*\)\s*\{[^}]*error[^}]*\}', content, re.DOTALL)
        api_analysis["error_handling"] = error_patterns
        
        # Analisar configura√ß√£o de timeout
        timeout_patterns = re.findall(r'timeout[^:]*:\s*\d+', content)
        api_analysis["timeout_configuration"] = timeout_patterns
        
        # Analisar mecanismos de retry
        retry_patterns = re.findall(r'retryCount|maxRetries|retry', content)
        api_analysis["retry_mechanisms"] = retry_patterns
        
        self.analysis_results["ai_nlp_analysis"]["translation_api_analysis"] = api_analysis
        print(f"üîó AI: API analisada - {len(endpoint_patterns)} endpoints, {len(retry_patterns)} mecanismos de retry")
        
    def _analyze_voice_synthesis_integration(self):
        """An√°lise AI da integra√ß√£o com s√≠ntese de voz"""
        print("üîä AI: Analisando integra√ß√£o com s√≠ntese de voz...")
        
        script_path = os.path.join(self.web_dir, "assets", "js", "script.js")
        
        with open(script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        synthesis_analysis = {
            "synthesis_calls": [],
            "voice_selection": [],
            "utterance_configuration": [],
            "synthesis_events": [],
            "error_recovery": []
        }
        
        # Analisar chamadas de s√≠ntese
        synthesis_calls = re.findall(r'speakTranslation\([^)]+\)', content)
        synthesis_analysis["synthesis_calls"] = synthesis_calls
        
        # Analisar sele√ß√£o de voz
        voice_selection = re.findall(r'getAvailableVoicesForLanguage|analyzeVoiceGender', content)
        synthesis_analysis["voice_selection"] = voice_selection
        
        # Analisar configura√ß√£o de utterance
        utterance_config = re.findall(r'new SpeechSynthesisUtterance|utterance\.[a-zA-Z]+\s*=', content)
        synthesis_analysis["utterance_configuration"] = utterance_config
        
        # Analisar eventos de s√≠ntese
        synthesis_events = re.findall(r'utterance\.on[a-zA-Z]+\s*=', content)
        synthesis_analysis["synthesis_events"] = synthesis_events
        
        self.analysis_results["ai_nlp_analysis"]["voice_synthesis_integration"] = synthesis_analysis
        print(f"üéµ AI: S√≠ntese analisada - {len(synthesis_calls)} chamadas, {len(synthesis_events)} eventos")
        
    def _analyze_error_patterns(self):
        """An√°lise NLP de padr√µes de erro"""
        print("üîç NLP: Analisando padr√µes de erro...")
        
        script_path = os.path.join(self.web_dir, "assets", "js", "script.js")
        
        with open(script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        error_patterns = {
            "voice_translation_errors": [],
            "api_failure_messages": [],
            "fallback_mechanisms": [],
            "user_error_messages": []
        }
        
        # Analisar erros espec√≠ficos de tradu√ß√£o por voz
        voice_errors = re.findall(r'Erro:.*?voz.*?Tente digitar manualmente', content)
        error_patterns["voice_translation_errors"] = voice_errors
        
        # Analisar mensagens de falha de API
        api_errors = re.findall(r'N√£o foi poss√≠vel traduzir|translation.*?failed', content, re.IGNORECASE)
        error_patterns["api_failure_messages"] = api_errors
        
        # Analisar mecanismos de fallback
        fallback_patterns = re.findall(r'getOfflineTranslation|emergency.*?translation', content, re.IGNORECASE)
        error_patterns["fallback_mechanisms"] = fallback_patterns
        
        self.analysis_results["ai_nlp_analysis"]["error_pattern_analysis"] = error_patterns
        print(f"‚ö†Ô∏è NLP: Padr√µes analisados - {len(voice_errors)} erros de voz, {len(fallback_patterns)} fallbacks")
        
    def _identify_specific_issues(self):
        """Identificar problemas espec√≠ficos baseados na an√°lise AI/NLP"""
        print("üéØ AI/NLP: Identificando problemas espec√≠ficos...")
        
        issues = []
        
        # Verificar se h√° problemas no pipeline de voz
        speech_pipeline = self.analysis_results["ai_nlp_analysis"]["speech_recognition_pipeline"]
        if len(speech_pipeline.get("recognition_initialization", [])) == 0:
            issues.append({
                "type": "speech_recognition_missing",
                "description": "Sistema de reconhecimento de voz n√£o inicializado corretamente",
                "severity": "critical",
                "ai_analysis": "NLP detectou aus√™ncia de inicializa√ß√£o de speech recognition"
            })
        
        # Verificar problemas na API de tradu√ß√£o
        api_analysis = self.analysis_results["ai_nlp_analysis"]["translation_api_analysis"]
        if len(api_analysis.get("error_handling", [])) < 2:
            issues.append({
                "type": "insufficient_error_handling",
                "description": "Tratamento de erro insuficiente nas chamadas de API",
                "severity": "high",
                "ai_analysis": "AI detectou tratamento de erro inadequado para APIs"
            })
        
        # Verificar integra√ß√£o com s√≠ntese de voz
        synthesis_analysis = self.analysis_results["ai_nlp_analysis"]["voice_synthesis_integration"]
        if len(synthesis_analysis.get("synthesis_calls", [])) > 0 and len(synthesis_analysis.get("synthesis_events", [])) < 3:
            issues.append({
                "type": "incomplete_synthesis_integration",
                "description": "Integra√ß√£o incompleta entre tradu√ß√£o e s√≠ntese de voz",
                "severity": "high",
                "ai_analysis": "AI detectou eventos de s√≠ntese insuficientes"
            })
        
        # Verificar padr√µes de erro espec√≠ficos
        error_patterns = self.analysis_results["ai_nlp_analysis"]["error_pattern_analysis"]
        if len(error_patterns.get("voice_translation_errors", [])) > 0:
            issues.append({
                "type": "voice_translation_error_pattern",
                "description": "Padr√£o de erro espec√≠fico detectado: 'N√£o foi poss√≠vel traduzir o texto por voz'",
                "severity": "critical",
                "ai_analysis": "NLP identificou padr√£o de erro recorrente em tradu√ß√£o por voz"
            })
        
        self.analysis_results["identified_issues"] = issues
        print(f"üö® AI/NLP: {len(issues)} problemas cr√≠ticos identificados")
        
    def apply_ai_nlp_fixes(self):
        """Aplicar corre√ß√µes baseadas em an√°lise AI/NLP"""
        print("üîß AI/NLP: Aplicando corre√ß√µes inteligentes...")
        
        script_path = os.path.join(self.web_dir, "assets", "js", "script.js")
        
        with open(script_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        fixes_applied = []
        
        # Fix 1: Melhorar pipeline de processamento de voz
        content = self._fix_voice_processing_pipeline(content)
        fixes_applied.append("Pipeline de processamento de voz otimizado")
        
        # Fix 2: Adicionar valida√ß√£o NLP robusta
        content = self._add_nlp_text_validation(content)
        fixes_applied.append("Valida√ß√£o NLP robusta adicionada")
        
        # Fix 3: Melhorar tratamento de erro com IA
        content = self._improve_ai_error_handling(content)
        fixes_applied.append("Tratamento de erro com IA melhorado")
        
        # Fix 4: Otimizar integra√ß√£o tradu√ß√£o-s√≠ntese
        content = self._optimize_translation_synthesis_integration(content)
        fixes_applied.append("Integra√ß√£o tradu√ß√£o-s√≠ntese otimizada")
        
        # Fix 5: Adicionar logs de diagn√≥stico AI/NLP
        content = self._add_ai_nlp_logging(content)
        fixes_applied.append("Logs de diagn√≥stico AI/NLP adicionados")
        
        # Salvar apenas se houve mudan√ßas
        if content != original_content:
            with open(script_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"‚úÖ AI/NLP: {len(fixes_applied)} corre√ß√µes aplicadas")
        
        self.analysis_results["applied_fixes"] = fixes_applied
        return fixes_applied
        
    def _fix_voice_processing_pipeline(self, content):
        """Corrigir pipeline de processamento de voz com AI/NLP"""
        # Adicionar processamento NLP robusto no onresult
        nlp_processing = """
            // ü§ñ AI/NLP: Processamento inteligente de voz
            recognition.onresult = (event) => {
                console.log('üé§ AI/NLP: Processando resultado de voz...');
                
                let transcript = '';
                let confidence = 0;
                
                // Processar todos os resultados com NLP
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const result = event.results[i];
                    
                    if (result.isFinal) {
                        transcript = result[0].transcript;
                        confidence = result[0].confidence || 0.8;
                        
                        console.log('ü§ñ AI/NLP: Texto final processado:', transcript);
                        console.log('üéØ AI/NLP: Confian√ßa:', confidence);
                        
                        // Valida√ß√£o NLP do texto
                        if (this.validateTextWithNLP(transcript, confidence)) {
                            this.elements.sourceText.value = transcript;
                            
                            // Tradu√ß√£o autom√°tica com processamento AI
                            if (this.autoTranslate) {
                                console.log('üöÄ AI/NLP: Iniciando tradu√ß√£o autom√°tica...');
                                this.translateTextWithSpeech(true);
                            }
                        } else {
                            console.warn('‚ö†Ô∏è AI/NLP: Texto rejeitado por valida√ß√£o NLP');
                        }
                    }
                }
                
                this.stopRecording();
            };"""
        
        # Substituir o onresult existente
        pattern = r'recognition\.onresult\s*=\s*\([^}]+\}\s*\);'
        return re.sub(pattern, nlp_processing, content, flags=re.DOTALL)
        
    def _add_nlp_text_validation(self, content):
        """Adicionar valida√ß√£o NLP robusta"""
        nlp_validation = """
        
        // ü§ñ AI/NLP: Valida√ß√£o inteligente de texto
        validateTextWithNLP(text, confidence = 0.8) {
            console.log('üîç AI/NLP: Validando texto com NLP...');
            
            // Valida√ß√µes b√°sicas de NLP
            if (!text || text.trim().length < 2) {
                console.warn('‚ùå AI/NLP: Texto muito curto');
                return false;
            }
            
            // Verificar confian√ßa m√≠nima
            if (confidence < 0.6) {
                console.warn('‚ùå AI/NLP: Confian√ßa muito baixa:', confidence);
                return false;
            }
            
            // Verificar se cont√©m apenas ru√≠do
            const noisePattern = /^[^a-zA-Z√Ä-√ø0-9\s]*$/;
            if (noisePattern.test(text)) {
                console.warn('‚ùå AI/NLP: Texto cont√©m apenas ru√≠do');
                return false;
            }
            
            // Verificar comprimento m√≠nimo de palavras
            const words = text.trim().split(/\s+/);
            if (words.length < 1) {
                console.warn('‚ùå AI/NLP: Nenhuma palavra v√°lida detectada');
                return false;
            }
            
            console.log('‚úÖ AI/NLP: Texto validado com sucesso');
            return true;
        }
        """
        
        # Inserir ap√≥s a classe NeuroTranslatorWeb
        pattern = r'(class NeuroTranslatorWeb \{[^}]+constructor\([^}]+\})'
        replacement = r'\g<1>' + nlp_validation
        return re.sub(pattern, replacement, content, flags=re.DOTALL)
        
    def _improve_ai_error_handling(self, content):
        """Melhorar tratamento de erro com IA"""
        ai_error_handling = """
                } catch (error) {
                    retryCount++;
                    console.error(`‚ùå AI/NLP: Erro na tentativa ${retryCount}:`, error);
                    
                    // ü§ñ AI: An√°lise inteligente do erro
                    const errorType = this.analyzeErrorWithAI(error);
                    console.log('üîç AI: Tipo de erro detectado:', errorType);
                    
                    if (retryCount >= maxRetries) {
                        // ü§ñ AI: Estrat√©gia inteligente de recupera√ß√£o
                        console.log('üö® AI/NLP: Aplicando estrat√©gia de recupera√ß√£o inteligente');
                        
                        try {
                            const emergencyTranslation = this.getOfflineTranslation(sourceText, sourceLang, targetLang);
                            if (emergencyTranslation) {
                                this.elements.targetText.value = emergencyTranslation;
                                this.elements.translationStatus.textContent = 'Tradu√ß√£o offline (AI/NLP)';
                                console.log('‚úÖ AI/NLP: Tradu√ß√£o de emerg√™ncia aplicada:', emergencyTranslation);
                                
                                // ü§ñ AI: S√≠ntese de voz com recupera√ß√£o inteligente
                                this.speakTranslationWithAI(emergencyTranslation, targetLang);
                            } else {
                                throw new Error('Tradu√ß√£o de emerg√™ncia tamb√©m falhou');
                            }
                        } catch (emergencyError) {
                            console.error('‚ùå AI/NLP: Falha total na tradu√ß√£o por voz:', emergencyError);
                            this.elements.translationStatus.textContent = 'Erro: Sistema de tradu√ß√£o temporariamente indispon√≠vel';
                            this.elements.targetText.value = 'Sistema temporariamente indispon√≠vel. Tente novamente em alguns segundos.';
                        }
                    } else {
                        // ü§ñ AI: Delay inteligente baseado no tipo de erro
                        const delay = this.calculateIntelligentDelay(errorType, retryCount);
                        console.log(`‚è≥ AI: Aguardando ${delay}ms antes da pr√≥xima tentativa`);
                        await new Promise(resolve => setTimeout(resolve, delay));
                    }
                }"""
        
        # Substituir o tratamento de erro existente na fun√ß√£o translateTextWithSpeech
        pattern = r'\} catch \(error\) \{[^}]+retryCount\+\+;[^}]+\}'
        return re.sub(pattern, ai_error_handling, content, flags=re.DOTALL)
        
    def _optimize_translation_synthesis_integration(self, content):
        """Otimizar integra√ß√£o entre tradu√ß√£o e s√≠ntese"""
        integration_optimization = """
        
        // ü§ñ AI: S√≠ntese de voz com intelig√™ncia artificial
        speakTranslationWithAI(text, language) {
            console.log('üîä AI: Iniciando s√≠ntese inteligente de voz...');
            
            if (!text || !text.trim()) {
                console.warn('‚ö†Ô∏è AI: Texto vazio para s√≠ntese');
                return;
            }
            
            // ü§ñ AI: Pr√©-processamento do texto para s√≠ntese
            const processedText = this.preprocessTextForSynthesis(text);
            
            // ü§ñ AI: Sele√ß√£o inteligente de voz
            this.selectOptimalVoiceWithAI(language).then(selectedVoice => {
                if (selectedVoice) {
                    console.log('‚úÖ AI: Voz otimizada selecionada:', selectedVoice.name);
                    this.speakTranslation(processedText, language);
                } else {
                    console.warn('‚ö†Ô∏è AI: Nenhuma voz adequada encontrada');
                    this.elements.speechStatus.textContent = '‚ö†Ô∏è S√≠ntese de voz n√£o dispon√≠vel';
                }
            });
        }
        
        // ü§ñ AI: Pr√©-processamento de texto para s√≠ntese
        preprocessTextForSynthesis(text) {
            // Remover caracteres problem√°ticos
            let processed = text.replace(/[^\w\s\.,!?;:-]/g, '');
            
            // Normalizar espa√ßos
            processed = processed.replace(/\s+/g, ' ').trim();
            
            // Limitar comprimento para evitar timeouts
            if (processed.length > 200) {
                processed = processed.substring(0, 200) + '...';
            }
            
            console.log('üîß AI: Texto pr√©-processado para s√≠ntese:', processed);
            return processed;
        }
        
        // ü§ñ AI: Sele√ß√£o otimizada de voz
        async selectOptimalVoiceWithAI(language) {
            const voices = speechSynthesis.getVoices();
            
            // Filtrar vozes por idioma
            const languageVoices = voices.filter(voice => 
                voice.lang.startsWith(language) || 
                voice.lang.startsWith(language.split('-')[0])
            );
            
            if (languageVoices.length > 0) {
                // Preferir vozes locais
                const localVoice = languageVoices.find(voice => voice.localService);
                return localVoice || languageVoices[0];
            }
            
            // Fallback para qualquer voz dispon√≠vel
            return voices.length > 0 ? voices[0] : null;
        }
        """
        
        # Inserir ap√≥s a fun√ß√£o speakTranslation
        pattern = r'(speakTranslation\([^}]+\}\s*\})'
        replacement = r'\g<1>' + integration_optimization
        return re.sub(pattern, replacement, content, flags=re.DOTALL)
        
    def _add_ai_nlp_logging(self, content):
        """Adicionar logs de diagn√≥stico AI/NLP"""
        ai_logging = """
        
        // ü§ñ AI/NLP: Sistema de an√°lise de erro inteligente
        analyzeErrorWithAI(error) {
            const errorMessage = error.message || error.toString();
            
            if (errorMessage.includes('network') || errorMessage.includes('fetch')) {
                return 'network_error';
            } else if (errorMessage.includes('timeout')) {
                return 'timeout_error';
            } else if (errorMessage.includes('synthesis') || errorMessage.includes('speech')) {
                return 'synthesis_error';
            } else if (errorMessage.includes('translation')) {
                return 'translation_error';
            } else {
                return 'unknown_error';
            }
        }
        
        // ü§ñ AI: C√°lculo de delay inteligente
        calculateIntelligentDelay(errorType, retryCount) {
            const baseDelay = 1000;
            const multipliers = {
                'network_error': 2,
                'timeout_error': 1.5,
                'synthesis_error': 1,
                'translation_error': 2.5,
                'unknown_error': 1.2
            };
            
            const multiplier = multipliers[errorType] || 1;
            return baseDelay * multiplier * retryCount;
        }
        """
        
        # Inserir no final da classe
        pattern = r'(\}\s*// Fim da classe NeuroTranslatorWeb)'
        replacement = ai_logging + '\n    ' + r'\g<1>'
        return re.sub(pattern, replacement, content)
        
    def generate_ai_nlp_report(self):
        """Gerar relat√≥rio da an√°lise AI/NLP"""
        report_path = os.path.join(self.web_dir, "ai_nlp_voice_diagnostic_report.json")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
        
        print(f"üìä AI/NLP: Relat√≥rio salvo em {report_path}")
        return report_path

def main():
    """Executar diagn√≥stico AI/NLP completo"""
    print("ü§ñ Iniciando MCP AI/NLP Voice Translation Diagnostic...")
    
    diagnostic = AIVoiceTranslationDiagnostic()
    
    # An√°lise completa
    diagnostic.run_comprehensive_analysis()
    
    # Aplicar corre√ß√µes
    fixes = diagnostic.apply_ai_nlp_fixes()
    
    # Gerar relat√≥rio
    report_path = diagnostic.generate_ai_nlp_report()
    
    print(f"\n‚úÖ AI/NLP: Diagn√≥stico e corre√ß√£o conclu√≠da!")
    print(f"üìã Corre√ß√µes aplicadas: {len(fixes)}")
    print(f"üìä Relat√≥rio: {report_path}")
    
    return diagnostic.analysis_results

if __name__ == "__main__":
    main()